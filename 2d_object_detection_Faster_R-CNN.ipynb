{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRdHGtPRuNOz2sXPcDrzGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbh4635/DL_studty/blob/main/2d_object_detection_Faster_R-CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# GPU 사용 설정\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "_gB75My5aH4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0514e20b-800a-4b13-d892-1696af98b60e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch기반 주요 Pre-trained 모델 라이브러리\n",
        "1. torchvision\n",
        "- pytorch 공식 제공 라이브러리, 안전성이 높으나 모델 업데이트가 늦어 제공되는 모델 수가 적음\n",
        "2. timm (Torch IMage Models)\n",
        "- pytorch기반 서드파티 라이브러리, 모델 업데이트가 빨라 많은 최신 백본을 제공함\n",
        "3. mmdet (MMDetection)\n",
        "- Object detection용 라이브러리, 최신 detection 모델이 많고 모듈화 구조로 다양한 백본과 Head를 조합하여 모델개발 용이\n",
        "4. Hugging Face Transformers\n",
        "- 여러 분야의 SotA 모델들이 빠르게 공유되는 오픈소스 라이브러리 (사내망 사용불가 - 보안예외 필요)"
      ],
      "metadata": {
        "id": "gFTWeTbIaUtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "# Faster R-CNN COCO pre-trained 모델 로드\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
        "\n",
        "weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
        "model = fasterrcnn_resnet50_fpn(weights=weights)\n",
        "# model = fasterrcnn_resnet50_fpn(pretrained=True) - 이것도 가능\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# MS COCO 데이터셋 클래스 이름 가져오기\n",
        "COCO_CATEGORIES = weights.meta[\"categories\"]"
      ],
      "metadata": {
        "id": "YvDjtR5lVIv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(COCO_CATEGORIES)\n",
        "len(COCO_CATEGORIES) # 실제 사용되는 class 수는 80개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydwz7tJK6G_H",
        "outputId": "df61a610-3535-49ed-bd3f-67455e9cf268"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 입력 이미지 다운로드"
      ],
      "metadata": {
        "id": "MwRPr8CEkWwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data\n",
        "!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg"
      ],
      "metadata": {
        "id": "oNcyqxJgVkmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV\n",
        "- 인텔이 개발한 Computer Vision 라이브러리\n",
        "- Python 이외에도 다양한 language 지원 (C++,C#,Java등)"
      ],
      "metadata": {
        "id": "NA_qjreigIn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 # OpenCV\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fname = './data/beatles01.jpg'\n",
        "\n",
        "# OpenCV로 이미지 읽기 'cv2.imread()'\n",
        "img = cv2.imread(fname)\n",
        "print('image shape:', img.shape) # (H,W,C)"
      ],
      "metadata": {
        "id": "V9nr5OtfWDZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_bgr = img\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(img_bgr)\n",
        "\n",
        "# 'cv2.cvtColor()'를 이용하여 BGR -> RGB 변환\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(img_rgb)"
      ],
      "metadata": {
        "id": "ltxXXfp0knKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.functional import to_tensor\n",
        "# 'to_tensor': 이미지 데이터를 [0,1] 사이 float값으로 Nomalization하고 tensor로 변환\n",
        "img_tensor = to_tensor(img_rgb).to(device)\n",
        "\n",
        "with torch.no_grad(): # gradient 계산 안함\n",
        "    outputs = model([img_tensor])  # list[dict]\n",
        "out = outputs[0]\n",
        "\n",
        "boxes = out[\"boxes\"].cpu()\n",
        "labels = out[\"labels\"].cpu()\n",
        "scores = out[\"scores\"].cpu()\n",
        "\n",
        "# 결과 확인\n",
        "print('box shape:', boxes.shape)\n",
        "print('label shape:', labels.shape)\n",
        "print('score shape:', scores.shape)"
      ],
      "metadata": {
        "id": "fCVo_Gcggs18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론결과 시각화 함수 정의 (이미지)"
      ],
      "metadata": {
        "id": "lS0dKELzw1_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_boxes_on_image(img_input, boxes, labels, scores, score_threshold=0.5):\n",
        "    \"\"\"\n",
        "    img_input : OpenCV 이미지 (np.ndarray)\n",
        "    boxes     : (N, 4) tensor [x1, y1, x2, y2]\n",
        "    labels    : (N,) tensor (int, COCO class index)\n",
        "    scores    : (N,) tensor (float)\n",
        "    \"\"\"\n",
        "    img = img_input.copy()\n",
        "    h, w = img.shape[:2]\n",
        "    box_color = (0, 255, 0) # green\n",
        "\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        if score < score_threshold:\n",
        "            continue\n",
        "\n",
        "        # 박스 설정\n",
        "        x1, y1, x2, y2 = box.int().tolist() # int로 변환(pixel 위치), tensor를 배열로 변경\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
        "\n",
        "        # 라벨 텍스트 설정\n",
        "        class_name = COCO_CATEGORIES[label]\n",
        "        text = f\"{class_name}: {score:.2f}\"\n",
        "\n",
        "        # 텍스트 배경 박스 설정\n",
        "        (tw, th), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "        cv2.rectangle(img, (x1, y1 - th - baseline), (x1 + tw, y1), box_color, -1)\n",
        "        cv2.putText(img, text, (x1, y1 - baseline),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "PX99k7reWQUw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 박스 그리기\n",
        "img_with_boxes = draw_boxes_on_image(img_rgb, boxes, labels, scores, score_threshold=0.5)\n",
        "\n",
        "# 모델 결과 확인\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(img_with_boxes)"
      ],
      "metadata": {
        "id": "a6ALF8yuilT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 입력 비디오 다운로드"
      ],
      "metadata": {
        "id": "rryTMCIytkDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O ./data/Jonh_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true"
      ],
      "metadata": {
        "id": "3fE0Wbattf_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vname = '/content/data/Jonh_Wick_small.mp4'\n",
        "\n",
        "# 'cv2.VideoCapture()'를 이용하여 비디오 객체를 생성\n",
        "cap = cv2.VideoCapture(vname)\n",
        "# 'cap.get()'은 비디오 객체의 다양한 속성값을 가져올 수 있음\n",
        "frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print('총 Frame 갯수:', frame_cnt)"
      ],
      "metadata": {
        "id": "L4AaWG9ut4Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론결과 시각화 함수 정의 (비디오)"
      ],
      "metadata": {
        "id": "W7eoi8y8xU5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_detection_on_video(model, video_path, output_path, score_threshold=0.5, speed_factor=1):\n",
        "    \"\"\"\n",
        "    model        : 추론 모델\n",
        "    video_path   : 입력 비디오 경로\n",
        "    output_path  : 출력 비디오 저장 경로\n",
        "    score_threshold : 바운딩 박스 신뢰도 threshold\n",
        "    speed_factor    : 출력 비디오 실행 배속 (fps*speed_factor)\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Cannot open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) # 입력 비디오의 fps\n",
        "    w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # 입력 비디오의 width\n",
        "    h  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 입력 비음오의 height\n",
        "\n",
        "    codec = cv2.VideoWriter_fourcc(*'mp4v') # or 'XVID'\n",
        "    out_writer = cv2.VideoWriter(output_path, codec, fps*speed_factor, (w, h))\n",
        "\n",
        "    frame_idx = 0\n",
        "    while True:\n",
        "        # 'cap.read()'는 마지막 Frame까지 차례대로 비디오를 읽음\n",
        "        has_frame, frame_bgr = cap.read() # [bool, image]\n",
        "        if not has_frame:\n",
        "            print('No frame available for video')\n",
        "            break\n",
        "\n",
        "        # BGR -> RGB\n",
        "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "        frame_tensor = to_tensor(frame_rgb).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model([frame_tensor])\n",
        "        out = outputs[0]\n",
        "\n",
        "        boxes = out[\"boxes\"].cpu()\n",
        "        labels = out[\"labels\"].cpu()\n",
        "        scores = out[\"scores\"].cpu()\n",
        "\n",
        "        frame_bgr = draw_boxes_on_image(frame_bgr, boxes, labels, scores, score_threshold)\n",
        "\n",
        "        # 저장시 이미지를 BGR 형태로 입력해야 RGB로 변환되어 저장됨\n",
        "        out_writer.write(frame_bgr)\n",
        "        frame_idx += 1\n",
        "        print(\"Frame: \", frame_idx)\n",
        "\n",
        "    cap.release()\n",
        "    out_writer.release()\n",
        "    print(f\"Saved video with detections: {output_path}\")"
      ],
      "metadata": {
        "id": "8mGrZmizuE75"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"outputs_videos\", exist_ok=True)\n",
        "\n",
        "in_path  = vname\n",
        "out_path = os.path.join(\"outputs_videos\", f\"det_{os.path.basename(vname)}\")\n",
        "\n",
        "run_detection_on_video(\n",
        "    model=model,\n",
        "    video_path=in_path,\n",
        "    output_path=out_path,\n",
        "    score_threshold=0.7,\n",
        "    speed_factor=0.3\n",
        ")"
      ],
      "metadata": {
        "id": "EQWr2iFkuNcq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}