{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbh4635/DL_studty/blob/main/multiclass_classification_CIFAR10_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습/검증 관련 함수 사전 정의"
      ],
      "metadata": {
        "id": "-DMVKsDDubba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXDSAV_D7gRj",
        "outputId": "5df697cc-5485-42eb-d829-e8b1756c86ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE) # GPU 설정 확인\n",
        "\n",
        "def Train(model, train_DL, criterion, optimizer, EPOCH):\n",
        "\n",
        "    loss_history =[]\n",
        "    NoT = len(train_DL.dataset)\n",
        "\n",
        "    model.train() # train mode로 전환\n",
        "    for ep in range(EPOCH):\n",
        "        rloss = 0 # running loss\n",
        "        for x_batch, y_batch in train_DL:\n",
        "            x_batch = x_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            # inference\n",
        "            y_hat = model(x_batch)\n",
        "            # loss\n",
        "            loss = criterion(y_hat, y_batch)\n",
        "            # update\n",
        "            optimizer.zero_grad() # gradient 누적을 막기 위한 초기화\n",
        "            loss.backward() # backpropagation\n",
        "            optimizer.step() # weight update\n",
        "            # loss accumulation\n",
        "            loss_b = loss.item() * x_batch.shape[0] # batch loss\n",
        "            rloss += loss_b # running loss\n",
        "        # print loss\n",
        "        loss_e = rloss/NoT\n",
        "        loss_history += [loss_e]\n",
        "        print(f\"Epoch: {ep+1}, train loss: {round(loss_e,3)}\")\n",
        "        print(\"-\"*20)\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "def Test(model, test_DL):\n",
        "    model.eval() # eval mode로 전환\n",
        "    with torch.no_grad():\n",
        "        rcorrect = 0\n",
        "        for x_batch, y_batch in test_DL:\n",
        "            x_batch = x_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            # inference\n",
        "            y_hat = model(x_batch)\n",
        "            # accuracy accumulation\n",
        "            pred = y_hat.argmax(dim=1)\n",
        "            corrects_b = torch.sum(pred == y_batch).item()\n",
        "            rcorrect += corrects_b\n",
        "        accuracy_e = rcorrect/len(test_DL.dataset)*100\n",
        "    print(f\"Test accuracy: {rcorrect}/{len(test_DL.dataset)} ({round(accuracy_e,1)} %)\")\n",
        "\n",
        "def Test_plot(model, test_DL):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_batch, y_batch = next(iter(test_DL))\n",
        "        x_batch = x_batch.to(DEVICE)\n",
        "        y_hat = model(x_batch)\n",
        "        pred = y_hat.argmax(dim=1)\n",
        "\n",
        "    x_batch = x_batch.to(\"cpu\")\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    for idx in range(6):\n",
        "        plt.subplot(2,3, idx+1, xticks=[], yticks=[])\n",
        "        plt.imshow(x_batch[idx].permute(1,2,0).squeeze(), cmap=\"gray\")\n",
        "        pred_class = test_DL.dataset.classes[pred[idx]]\n",
        "        true_class = test_DL.dataset.classes[y_batch[idx]]\n",
        "        plt.title(f\"{pred_class} ({true_class})\", color = \"g\" if pred_class==true_class else \"r\")\n",
        "\n",
        "def count_params(model):\n",
        "    num = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "    return num"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 파라미터 정의"
      ],
      "metadata": {
        "id": "3aWnwWzNuq47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "LR = 1e-3\n",
        "EPOCH = 5\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "c9ibKHvT8LWr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 로드"
      ],
      "metadata": {
        "id": "Vk89mLEtuvKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "train_DS = datasets.CIFAR10(root = '/content/ data', train=True, download=True, transform=transform)\n",
        "test_DS = datasets.CIFAR10(root = '/content/ data', train=False, download=True, transform=transform)\n",
        "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "-gA1mW648UPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_DS)\n",
        "print(test_DS)\n",
        "print(len(train_DS))\n",
        "print(len(test_DS))"
      ],
      "metadata": {
        "id": "M8v3gWCF8e9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_DS.classes)\n",
        "print(test_DS.class_to_idx)\n",
        "\n",
        "# DataLoader로 한국자 퍼내기\n",
        "x_batch, y_batch = next(iter(test_DL))\n",
        "print(x_batch.shape)\n",
        "\n",
        "plt.imshow(x_batch[0].permute(1,2,0)) # (C,H,W)->(H,W,C)\n",
        "print(test_DS.classes[y_batch[0]])"
      ],
      "metadata": {
        "id": "0TBMcByR8qIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP 모델 정의"
      ],
      "metadata": {
        "id": "2jh181M7uWEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # MLP의 은닉층 노드 수 - 하이퍼 파리미터\n",
        "        hidden_dim = 100\n",
        "\n",
        "        # MLP layer 정의\n",
        "        self.linear = nn.Sequential(nn.Linear(3*32*32, hidden_dim), # 입력 노드 수: 3*32*32 (MNIST는 28*28)\n",
        "                                    nn.ReLU(), # activation func\n",
        "                                    nn.Linear(hidden_dim,10)) # 출력 노드 수: 10 (총 class 개수)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # MLP는 CNN과 다르게 2d 이미지를 바로 처리 못하므로 flatten 매서드를 통해 평탄화함\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "INEtEr_g9eDV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN 모델 정의"
      ],
      "metadata": {
        "id": "eWPEWT9auY_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3,8,3, padding=1), # (입력 채널, 출력 채널, 커널 사이즈)\n",
        "                                   nn.BatchNorm2d(8), # (입력채널)\n",
        "                                   nn.ReLU())\n",
        "        self.Maxpool1 = nn.MaxPool2d(2) # (커널 사이즈) - 다운 스케일링\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(8,16,3, padding=1),\n",
        "                                   nn.BatchNorm2d(16),\n",
        "                                   nn.ReLU())\n",
        "        self.Maxpool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(16,32,3, padding=1),\n",
        "                                   nn.BatchNorm2d(32),\n",
        "                                   nn.ReLU())\n",
        "        self.Maxpool3 = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(32*4*4, 10) # (최종입력 채널 * Feature map Size, 클래스 수)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.Maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.Maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.Maxpool3(x)\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class CNN_deep(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_block1 = nn.Sequential(nn.Conv2d(3,32,3,padding=1),\n",
        "                                         nn.BatchNorm2d(32),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Conv2d(32,32,3,padding=1),\n",
        "                                         nn.BatchNorm2d(32),\n",
        "                                         nn.ReLU())\n",
        "        self.Maxpool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(nn.Conv2d(32,64,3,padding=1),\n",
        "                                         nn.BatchNorm2d(64),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Conv2d(64,64,3,padding=1),\n",
        "                                         nn.BatchNorm2d(64),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Conv2d(64,64,3,padding=1),\n",
        "                                         nn.BatchNorm2d(64),\n",
        "                                         nn.ReLU())\n",
        "        self.Maxpool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(nn.Conv2d(64,128,3,padding=1),\n",
        "                                         nn.BatchNorm2d(128),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Conv2d(128,128,3,padding=1),\n",
        "                                         nn.BatchNorm2d(128),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Conv2d(128,128,3,padding=1),\n",
        "                                         nn.BatchNorm2d(128),\n",
        "                                         nn.ReLU())\n",
        "        self.Maxpool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Linear(128*4*4,512),  # (최종입력 채널 * Feature map Size, 출력 채널)\n",
        "                                        nn.ReLU(), # activation func\n",
        "                                        nn.Linear(512,10)) # 출력 노드 수: 10 (총 class 개수)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.Maxpool1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.Maxpool2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.Maxpool3(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "j5p4OzuP9P1B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 설정"
      ],
      "metadata": {
        "id": "Ym05KD0Lvk5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장 경로 설정\n",
        "os.makedirs(\"/content/test_result\", exist_ok=True)\n",
        "\n",
        "new_model_train = True\n",
        "model_type = \"MLP\"\n",
        "dataset = \"CIFAR10\"\n",
        "save_model_path = f\"/content/test_result/{model_type}_{dataset}.pt\"\n",
        "\n",
        "exec(f\"model = {model_type}().to(DEVICE)\") # 모델 GPU에 올리기\n",
        "print(model) # 모델 구성 확인\n",
        "\n",
        "x_batch, _ = next(iter(train_DL))\n",
        "print('모델 최종출력 Tensor: ',model(x_batch.to(DEVICE)).shape)"
      ],
      "metadata": {
        "id": "6e2YvzdzkEt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련"
      ],
      "metadata": {
        "id": "ZCtsUjzju-2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if new_model_train:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR) # Adam 사용\n",
        "    loss_history = Train(model, train_DL, criterion, optimizer, EPOCH)\n",
        "\n",
        "    torch.save(model, save_model_path)\n",
        "\n",
        "    plt.plot(range(1,EPOCH+1),loss_history)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title(\"Train Loss\")\n",
        "    plt.grid()\n",
        "\n",
        "    new_model_train = False\n",
        "    load_model = model\n",
        "else:\n",
        "    print('Model load')\n",
        "    load_model = torch.load(save_model_path, map_location=DEVICE, weights_only=False)"
      ],
      "metadata": {
        "id": "jF3CJdHj9XUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2754eea-70ef-428e-c2fd-812df675c12a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 결과 확인"
      ],
      "metadata": {
        "id": "8Zvz2cVeuSYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Test(load_model, test_DL)\n",
        "print('모델 파라미터 수: ', count_params(load_model))"
      ],
      "metadata": {
        "id": "yWnlmf2p936B",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_plot(load_model, test_DL)"
      ],
      "metadata": {
        "id": "tzXRFB739-St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN 모델의 Feature map 시각화"
      ],
      "metadata": {
        "id": "Q0YS1HTgvD0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_model=torch.load(\"/content/test_result/CNN_deep_CIFAR10.pt\", map_location=DEVICE, weights_only=False)\n",
        "tmp_DL = torch.utils.data.DataLoader(test_DS, batch_size=1, shuffle=True)\n",
        "\n",
        "load_model.eval()\n",
        "with torch.no_grad():\n",
        "    x_batch, y_batch = next(iter(tmp_DL))\n",
        "    x_batch = x_batch.to(DEVICE)\n",
        "    y_batch = y_batch.to(DEVICE)\n",
        "    y_hat = load_model(x_batch)\n",
        "    pred = y_hat.argmax(dim=1)\n",
        "\n",
        "    feature_map1 = load_model.conv_block1(x_batch)\n",
        "    feature_map2 = load_model.conv_block2(load_model.Maxpool1(feature_map1))\n",
        "    feature_map3 = load_model.conv_block3(load_model.Maxpool2(feature_map2))\n",
        "\n",
        "x_batch = x_batch.cpu()\n",
        "feature_map1 = feature_map1.cpu()\n",
        "feature_map2 = feature_map2.cpu()\n",
        "feature_map3 = feature_map3.cpu()\n",
        "\n",
        "print(test_DS.classes[y_batch])\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.xticks([]); plt.yticks([])\n",
        "plt.imshow(x_batch[0,...].permute(1,2,0))\n",
        "\n",
        "print(feature_map1.shape)\n",
        "plt.figure(figsize=(32,16))\n",
        "for idx in range(32):\n",
        "    plt.subplot(4,8,idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(feature_map1[0,idx,...], cmap=\"gray\")\n",
        "\n",
        "print(feature_map2.shape)\n",
        "plt.figure(figsize=(16,16))\n",
        "for idx in range(64):\n",
        "    plt.subplot(8,8,idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(feature_map2[0,idx,...], cmap=\"gray\")\n",
        "\n",
        "print(feature_map3.shape)\n",
        "plt.figure(figsize=(16,8))\n",
        "for idx in range(128):\n",
        "    plt.subplot(8,16,idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(feature_map3[0,idx,...], cmap=\"gray\")"
      ],
      "metadata": {
        "id": "zJTgBXQVpnFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 결과: 보라색(최소값) -> 남색 -> 초록색 -> 노란색(최대값)\n",
        "summed_map = feature_map3.abs().sum(dim=1)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.xticks([]); plt.yticks([])\n",
        "plt.imshow(summed_map[0,...], cmap='viridis')\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.xticks([]); plt.yticks([])\n",
        "plt.imshow(x_batch[0,...].permute(1,2,0))\n",
        "plt.imshow(summed_map[0,...], extent=[0,32,32,0], alpha=0.4, cmap='viridis')\n",
        "pred_class = test_DS.classes[pred]\n",
        "true_class = test_DS.classes[y_batch]\n",
        "plt.title(f\"{pred_class} ({true_class})\", color=\"g\" if pred_class==true_class else \"r\")"
      ],
      "metadata": {
        "id": "nbbEKY3MqvDq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}